# the teams or use cases accessing Azure OpenAI (aka. "clients")
# notes: - each client must have a unique key. PowerProxy identifies clients by the given key.
#        - one and only one client can use "uses_entra_id_auth: true" instead of a key. this client is used for all
#          requests where an Entra ID/Azure AD authentication shall be used instead of an API key authentication.
clients:
  - name: Team 1
    description: An example team named 'Team 1'.
    key: 28ef59ae30342978f81c4ad96ce47ab
    deployments_allowed: gpt-35-turbo, gpt-4o
    max_tokens_per_minute_in_k:
      gpt-35-turbo: 20
      gpt-4o: 5
  - name: Team 2
    description: An example team named 'Team 2'.
    key: 1113456789abcdef0123456789abcde
    deployments_allowed:
      - gpt-35-turbo
      - gpt-4o
    max_tokens_per_minute_in_k: 30
  - name: Test Script Client 1
    description: Used by the included test scripts.
    key: 04ae14bc78184621d37f1ce57a52eb7
    deployments_allowed: [gpt-35-turbo, gpt-4o]
    max_tokens_per_minute_in_k: 5
  - name: Test Script Client 2
    description: Used by the included test scripts.
    key: 72bd81ef32763530b29e3da63d46ad6
    deployments_allowed: gpt-35-turbo, gpt-4o
    max_tokens_per_minute_in_k: 5
  - name: Entra ID Auth Client
    description: Client used whenever a client authenticates via Entra ID / Azure AD.
    uses_entra_id_auth: true
    deployments_allowed: gpt-35-turbo, gpt-4o
    max_tokens_per_minute_in_k: 10

# defines the plugins enabled for the proxy
plugins:
  - name: AllowDeployments
  - name: LimitUsage
    # remove the redis field if no redis synchronization is desired
    # note: do that only in case of a single PowerProxy worker where no synchronization is needed
    redis:
      redis_host: <will be set by deployment script>
      redis_password: <will be set by deployment script>
  - name: LogUsageToConsole
  - name: LogUsageToCsvFile
  - name: LogUsageToLogAnalytics
    log_ingestion_endpoint: <will be set by deployment script>
    data_collection_rule_id: <will be set by deployment script>
    # By default, the DefaultAzureCredential class is used to authenticate against Log Analytics, which automatically
    # tries workload identites, system-managed managed identities, etc. However, if a
    # user_assigned_managed_identity_client_id is specified in this config file below, that user-assigned managed
    # identity will be used. Alternatively, credentials of a service principal can be specified here by using the
    # following fields.
    #credential_tenant_id: ___
    #credential_client_id: ___
    #credential_client_secret: ___
    # In any case, make sure that the used identity has the "Monitoring Metrics Publisher" role assigned to the Data
    # Collection Rule (it might take up to 30 minutes to become effective after configuration).

# Azure OpenAI
aoai:
  endpoints:
    - name: Some Endpoint
      url: https://___.openai.azure.com/
      # not required when clients send their own bearer token or when DefaultAzureCredentials are to be used for the
      # authentication against AOAI (for example: Managed Identity, Workload Identity, Azure CLI Credentials etc.)
      key: ___
      # fraction of non-streaming requests handled
      # 0   = endpoint will handle no non-streaming request
      # 0.7 = endpoint will handle 70% of the non-streaming requests it gets
      # 1   = endpoint will handle all non-streaming request it gets
      non_streaming_fraction: 1

      # exclude usage of an endpoint during the day
      exclude_day_usage: true
      # if daily usage must be excluded, then begin and end of the day must be specified in UTC
      nightly_begin_utc: "06:00"
      nightly_end_utc: "16:00"

      # optional: custom connection limits and timeouts. uses values below as defaults if not specified.
      # notes: - if this is run via the Dockerfile provided, additional adjustments in the Dockerfile might be required.
      #        - use with care and only if needed, defaults should be good in most cases
      connections:
        limits:
          max_connections: 100
          max_keepalive_connections: 20
          keepalive_expiry: 5
        timeouts:
          connect: 15
          read: 120
          write: 120
          pool: 120
      # optional: endpoints can also have "virtual deployments" (optional). when a virtual deployment is defined,
      # requests requesting specific deployments are rewritten such that a smart load balancing across the listed
      # "stand-ins" = real deployments at the endpoint happens. similar to the non_streaming_fraction at the endpoint
      # level, we can also set non_streaming_fractions for stand-ins.
      virtual_deployments:
        - name: gpt-35-turbo
          standins:
            - name: gpt-35-turbo-ptu
              non_streaming_fraction: 0.2
            - name: gpt-35-turbo-paygo
        - name: gpt-4o
          standins:
            - name: gpt-4o-ptu
              non_streaming_fraction: 0.2
            - name: gpt-4o-paygo

    - name: Another Endpoint
      # ... (see above)

  # # alternatively, specify a mock response to be used instead of the real response from
  # # Azure OpenAI
  # # note: use this for testing PowerProxy's scalability
  # mock_response:
  #   ms_to_wait_before_return: 1000
  #   json: {
  #     "id": "chatcmpl-87lITNUXLFIBHyDu3jFTtgOibcAxz",
  #     "object": "chat.completion",
  #     "created": 1696860797,
  #     "model": "gpt-35-turbo",
  #     "choices": [
  #       {
  #         "index": 0,
  #         "finish_reason": "stop",
  #         "message": {
  #           "role": "assistant",
  #           "content": "I'm a mock response and not a real answer from Azure OpenAI."
  #         }
  #       }
  #     ],
  #     "usage": {
  #       "completion_tokens": 16,
  #       "prompt_tokens": 61,
  #       "total_tokens": 77
  #     }
  #   }

# id of the Azure subscription where the proxy shall be deployed to
azure_subscription_id: ___

# region to which the proxy shall be deployed to Azure
# example: westeurope
region: ___

# resource group to which the proxy shall be deployed to Azure
# example: PowerProxy-AOAI
resource_group: ___

# unique prefix to prepend to certain resource names to avoid naming conflicts.
# example: abcde
unique_prefix: ___

# id of the user-assigned managed identity
# note: PowerProxy will assume a system-assigned managed or workload identity if not specified
user_assigned_managed_identity_client_id: <will be set by deployment script>
